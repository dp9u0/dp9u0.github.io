<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[sql server 锁(2)]]></title>
      <url>%2F2017%2F03%2F24%2Fsql-server-locks-part-ii%2F</url>
      <content type="text"><![CDATA[继续学习锁。 准备下载巨硬提供的AdventureWorks,下载的是2014版本.是bak文件，直接恢复数据库就可以了. 如果比较旧的版本，例如2008R2，提供的是下载的是 mdf和ldf.可以用CRTEATE DATABASE 命令，从文件创建： 12CREATE DATABASE AdventureWorksON (FILENAME = 'C:\Data\AdventureWorks2008R2_Data.mdf'), (FILENAME = 'C:\Data\AdventureWorks2008R2_Log.ldf') FOR ATTACH; 创建完成后，创建需要的表： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182----------------------------------------------B树表聚集索引表-------------------------------------------USE [AdventureWorks]GOIF EXISTS ( SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'Employee_Demo_BTree') DROP TABLE Employee_Demo_BTreeGOCREATE TABLE Employee_Demo_BTree( EmployeeID INT NOT NULL PRIMARY KEY, NationalIDNumber NVARCHAR(15) NOT NULL, ContactID INT NOT NULL, LoginID NVARCHAR(256) NOT NULL, ManagerID INT NULL, Title NVARCHAR(50) NOT NULL, BirthDate DATETIME NOT NULL, MaritalStatus NCHAR(1) NOT NULL, Gender NCHAR(1) NOT NULL, HireDate DATETIME NOT NULL, ModifiedDate DATETIME NOT NULL DEFAULT GETDATE())GO--主键就已经是聚集索引了,无需再指定--CREATE CLUSTERED INDEX PK_Employee_EmployeeID_Demo_BTree ON Employee_Demo_BTree(EmployeeID ASC)--添加非聚集索引CREATE NONCLUSTERED INDEX IX_Employee_ManagerID_Demo_BTree ON Employee_Demo_BTree([ManagerID] ASC)CREATE NONCLUSTERED INDEX IX_Employee_ModifiedDate_Demo_BTree ON Employee_Demo_BTree( [ModifiedDate] ASC)--插入数据INSERT [dbo].[Employee_Demo_BTree] SELECT [BusinessEntityID], [NationalIDNumber], [BusinessEntityID]+100, [LoginID], [BusinessEntityID]%50, [JobTitle], [BirthDate], [MaritalStatus], [Gender], [HireDate], [ModifiedDate] FROM [HumanResources].[Employee]GO----------------------------------------------堆表非聚集索引表-------------------------------------------USE [AdventureWorks]GOIF EXISTS(SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'Employee_Demo_Heap') DROP TABLE Employee_Demo_HeapGOCREATE TABLE Employee_Demo_Heap( EmployeeID INT NOT NULL, NationalIDNumber NVARCHAR(15) NOT NULL, ContactID INT NOT NULL, LoginID NVARCHAR(256) NOT NULL, ManagerID INT NULL, Title NVARCHAR(50) NOT NULL, BirthDate DATETIME NOT NULL, MaritalStatus NCHAR(1) NOT NULL, Gender NCHAR(1) NOT NULL, HireDate DATETIME NOT NULL, ModifiedDate DATETIME NOT NULL DEFAULT GETDATE())GO--因为没有主键所以要指定非聚集索引CREATE NONCLUSTERED INDEX PK_Employee_EmployeeID_Demo_Heap ON Employee_Demo_Heap( [EmployeeID] ASC)--添加非聚集索引CREATE NONCLUSTERED INDEX IX_Employee_ManagerID_Demo_Heap ON Employee_Demo_BTree([ManagerID] ASC)CREATE NONCLUSTERED INDEX IX_Employee_ModifiedDate_Demo_Heap ON Employee_Demo_BTree( [ModifiedDate] ASC)--插入数据INSERT [dbo].[Employee_Demo_Heap] SELECT [BusinessEntityID], [NationalIDNumber], [BusinessEntityID]+100, [LoginID], [BusinessEntityID]%50, [JobTitle], [BirthDate], [MaritalStatus], [Gender], [HireDate], [ModifiedDate] FROM [HumanResources].[Employee]GO 监视锁申请、持有和释放该语句可以查看当前锁申请、持有等情况： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586SELECT GETDATE()AS 'current_time' --回话id ,CASE es.session_id WHEN -2 THEN 'Orphaned Distributed Transaction' WHEN -3 THEN 'Deferred Recovery Transaction' ELSE es.session_id END AS spid --锁资源情况 ,db_name(sp.dbid)AS database_name ,CASE WHEN tl.resource_type = 'OBJECT' THEN OBJECT_NAME(tl.resource_associated_entity_id) WHEN tl.resource_type IN ('KEY', 'PAGE', 'RID') THEN (SELECT object_name(object_id) FROM sys.partitions AS ps1 WHERE ps1.hobt_id = tl.resource_associated_entity_id) ELSE '' END AS lock_object_name ,tl.resource_type AS lock_resource ,tl.request_mode AS lock_mode ,tl.resource_associated_entity_id AS lock_resource_id ,tl.resource_description AS lock_resource_info ,tl.request_status AS lock_status --回话信息 --,es.status AS session_status --,es.host_name --,es.login_time --,es.login_name --,es.program_name --,CONVERT(float, ROUND((ISNULL(es.cpu_time, 0.0)/1000.00), 0))AS cpu_time --,CONVERT(float, ROUND((ISNULL(es.lock_timeout, 0.0)/1000.00), 0))AS lock_timeout --事务信息 ,tat.name AS trans_name ,CASE tst.is_user_transaction WHEN 0 THEN 'system' WHEN 1 THEN 'user' END AS trans_type ,substring((SELECT text FROM sys.dm_exec_sql_text(sp.sql_handle)), 1, 128) AS sql_text ,CASE er.transaction_isolation_level WHEN 0 THEN 'Unspecified' WHEN 1 THEN 'Read Uncomitted' WHEN 2 THEN 'Read Committed' WHEN 3 THEN 'Repeatable' WHEN 4 THEN 'Serializable' WHEN 5 THEN 'Snapshot' ELSE '' END transaction_isolation_level --连接信息 --,er.connection_id ,CASE er.blocking_session_id WHEN -2 THEN 'Orphaned Distributed Transaction' WHEN -3 THEN 'Deferred Recovery Transaction' WHEN -4 THEN 'Latch Owner Not Determined' ELSE er.blocking_session_id END AS blocking_by ,er.wait_type --,CONVERT(float, ROUND((ISNULL(er.wait_time, 0.0)/1000.00), 0))AS wait_time --,er.percent_complete --,er.estimated_completion_time --,CONVERT(float, ROUND((ISNULL(er.total_elapsed_time, 0.0)/1000.00), 0))AS total_elapsed_time --,ec.connect_time --,ec.net_transport --,ec.client_net_addressFROM master.sys.dm_exec_sessions AS esINNER JOIN master.sys.sysprocesses AS sp ON sp.spid = es.session_idLEFT JOIN master.sys.dm_exec_connections AS ec ON ec.session_id = es.session_idLEFT JOIN master.sys.dm_exec_requests AS er ON er.session_id = es.session_idLEFT JOIN master.sys.dm_tran_locks AS tl ON tl.request_session_id = es.session_id LEFT JOIN master.sys.dm_tran_session_transactions AS tst ON es.session_id = tst.session_idLEFT JOIN master.sys.dm_tran_active_transactions AS tat ON tst.transaction_id = tat.transaction_idWHERE spid &lt;&gt; @@spid/* IGNORE CURRENT SESSION */AND sp.dbid = db_id()/* CURRENT DB TO MONITOR */ORDER BY spid,database_name,lock_object_name,lock_resource 实际查询中锁的申请与释放SELECT实验112345678910111213141516171819202122232425262728293031--select动作要申请的锁(1)--聚集表SET TRANSACTION ISOLATION LEVEL REPEATABLE READ --REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOBEGIN TRAN select_from_btree_1SELECT[EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_BTree]WHERE [EmployeeID]=3--COMMIT TRAN--ROLLBACK--1-- DATABASE,,S, --2-- Employee_Demo_BTree,OBJECT,IS --3-- Employee_Demo_BTree,KEY,S,(98ec012aa510)--4-- Employee_Demo_BTree,PAGE,IS,1:24345 --1.因为连接正在访问数据库[AdventureWorks],所以在数据库一级加了一个共享锁,以防止别人将数据库删除--2.因为正在访问表格[Employee_Demo_BTree]，所以在表格上加了一个意向共享锁,以防止别人修改表的定义--3.查询有1条记录返回,所以在这1条记录所在的聚集索引键上,持有一个共享锁。--4.在这个聚集索引键所在的页(因为是聚集索引,因此键所在的叶子是数据页)上持有一个意向共享锁 实验2123456789101112131415161718192021222324252627282930313233--select动作要申请的锁(2)--堆表SET TRANSACTION ISOLATION LEVEL REPEATABLE READ --REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOBEGIN TRAN select_from_heap_2SELECT[EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_Heap]WHERE [EmployeeID]=3--COMMIT TRAN--ROLLBACK--1-- ,DATABASE,S,--2-- Employee_Demo_Heap,OBJECT,IS,--3-- Employee_Demo_Heap,KEY,S,(99944d58347a) --4-- Employee_Demo_Heap,RID,S,1:24344:2--5-- Employee_Demo_Heap,PAGE,IS,1:24353 --6-- Employee_Demo_Heap,PAGE,IS,1:24344 --1.因为连接正在访问数据库[AdventureWorks],所以在数据库一级加了一个共享锁,以防止别人将数据库删除--2.因为正在访问表格[Employee_Demo_Heap]，所以在表格上加了一个意向共享锁,以防止别人修改表的定义--3-4.通过非聚集键找到数据RID,再通过RID查找到数据（即书签查找 bookmark lookup）,因此对这个非聚集索引键和数据的RID分别持有一个共享锁--5-6.Key和RID(数据页)所在的页面上分别持有一个IS锁。 实验31234567891011121314151617181920212223242526272829303132--select动作要申请的锁(3)--聚集表SET TRANSACTION ISOLATION LEVEL REPEATABLE READ--REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOBEGIN TRAN select_from_btree_3SELECT [EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_BTree] WHERE [EmployeeID] IN(3,30,200)--COMMIT TRAN--ROLLBACK--1-- ,DATABASE,S,--2-- Employee_Demo_BTree,OBJECT,IS, --3-- Employee_Demo_BTree,KEY,S,(98ec012aa510) --4-- Employee_Demo_BTree,KEY,S,(af5579654878) --5-- Employee_Demo_BTree,KEY,S,(8034b699f2c9) --6-- Employee_Demo_BTree,PAGE,IS,1:24183 --7-- Employee_Demo_BTree,PAGE,IS,1:24345 --1.因为连接正在访问数据库[AdventureWorks],所以在数据库一级加了一个共享锁,以防止别人将数据库删除--2.因为正在访问表格[Employee_Demo_BTree]，所以在表格上加了一个意向共享锁,以防止别人修改表的定义--3-5.查询有3条记录返回,所以在这3条记录所在的聚集索引键上,分别持有一个共享锁。--6-7.在这3个数据分布在2个页上,在两个页上分别持有一个意向共享锁 实验412345678910111213141516171819202122232425262728293031323334353637--select动作要申请的锁(4)--堆表SET TRANSACTION ISOLATION LEVEL REPEATABLE READ--REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOSET STATISTICS IO ONGOBEGIN TRAN select_from_heap_4SELECT [EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_Heap] --with (index (PK_Employee_EmployeeID_Demo_Heap))WHERE [EmployeeID] IN(3,30,200)--COMMIT TRAN--ROLLBACK--1-- ,DATABASE,S, --2-- Employee_Demo_Heap,OBJECT,IS, --3-- Employee_Demo_Heap,PAGE,IS,1:24360 --4-- Employee_Demo_Heap,PAGE,IS,1:24359 --5-- Employee_Demo_Heap,PAGE,IS,1:24358 --6-- Employee_Demo_Heap,PAGE,IS,1:24357 --7-- Employee_Demo_Heap,PAGE,IS,1:24356 --8-- Employee_Demo_Heap,PAGE,IS,1:24355 --9-- Employee_Demo_Heap,PAGE,IS,1:24344 --10--Employee_Demo_Heap,RID,S,1:24344:29 --11--Employee_Demo_Heap,RID,S,1:24358:16 --12--Employee_Demo_Heap,RID,S,1:24344:2 --1.因为连接正在访问数据库[AdventureWorks],所以在数据库一级加了一个共享锁,以防止别人将数据库删除--2-9.查询计划分析后发现 Index Seek（9次逻辑读 --with (index (PK_Employee_EmployeeID_Demo_Heap))）开销比 Table Scan(7次逻辑读) 大,因此决定使用 Table Scan,因此在所有页面上添加IS--10-12 读取到的数据RID加S锁 实验5123456789101112131415161718192021222324252627282930313233343536373839404142434445464748--会话1BEGIN TRAN update_heap_5UPDATE [dbo].[Employee_Demo_Heap]SET [Title]='aaa'WHERE [EmployeeID]=70--COMMIT TRAN--ROLLBACK--会话2SET TRANSACTION ISOLATION LEVEL REPEATABLE READ --REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOSET STATISTICS IO ONGOBEGIN TRAN select_from_heap_5SELECT [EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_Heap] WHERE [EmployeeID] IN(3,80,200)--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_Heap,OBJECT,IS, --Employee_Demo_Heap,PAGE,IS,1:24344 --Employee_Demo_Heap,PAGE,IS,1:24360 --Employee_Demo_Heap,PAGE,IS,1:24359 --Employee_Demo_Heap,PAGE,IS,1:24358 --Employee_Demo_Heap,PAGE,IS,1:24357 --Employee_Demo_Heap,PAGE,IS,1:24356 --Employee_Demo_Heap,PAGE,IS,1:24355 --Employee_Demo_Heap,RID,S,1:24355:32 --Employee_Demo_Heap,RID,S,1:24358:16 --Employee_Demo_Heap,RID,S,1:24344:2 --Table Scan 时候会逐个获取 RID 的 S 锁 但是 Update 持有了 ID=70的 X锁--因此select 会被阻塞--但是当获取到ID=70的锁后 发现不需要返回该数据 --因此会释放ID-70的数据的S锁 实验61234567891011121314151617181920212223242526272829303132333435363738394041--会话1BEGIN TRAN update_heap_6UPDATE [dbo].[Employee_Demo_BTree]SET [Title]='aaa'WHERE [EmployeeID]=70--COMMIT TRAN--ROLLBACK--会话2SET TRANSACTION ISOLATION LEVEL REPEATABLE READ --REPEATABLE READ 会一直持有S锁 直到事务结束GOSET STATISTICS PROFILE ONGOSET STATISTICS IO ONGOBEGIN TRAN select_from_beetree_6SELECT [EmployeeID],[LoginID],[Title]FROM [dbo].[Employee_Demo_BTree] WHERE [EmployeeID] IN(3,80,200)--COMMIT TRAN--ROLLBACK--使用Clustered Index Seek 不会扫描到 不需要的数据（例如ID=70） 因此不会被Update 阻塞--,DATABASE,S, --Employee_Demo_BTree,KEY,S,(98ec012aa510) --Employee_Demo_BTree,KEY,S,(af5579654878) --Employee_Demo_BTree,KEY,S,(d2e40430031e) --Employee_Demo_BTree,OBJECT,IS, --Employee_Demo_BTree,PAGE,IS,1:24183 --Employee_Demo_BTree,PAGE,IS,1:24178 --Employee_Demo_BTree,PAGE,IS,1:24345 总结 查询在运行过程中，会对每一条读到的记录或键值加共享锁。如果记录不用返回。那锁就会被释放。如果记录需要被返回，则视隔离级别而定，如果是“已提交读”，则也释放否则，不释放 对每一个使用到的索引，SQL也会对上面的键值加共享锁 对每个读过的页面，SQL会加一个意向锁 查询需要扫描页面和记录越多，锁的数目也会越多。查询用到的索引越多，锁的数目也会越多 当然，这些对于“已提交读”以上隔离级别而言。如果使用“未提交读”，SQL就不会申请这些共享锁阻塞也不会发生 避免阻塞采取的方法 尽量返回少的记录集，返回的结果越多，需要的锁也就越多 如果返回结果集只是表格所有记录的一小部分，要尽量使用index seek，避免全表扫描这种执行计划 可能的话，设计好合适的索引，避免SQL通过多个索引才找到数据 UPDATE实验11234567891011121314151617181920212223242526272829303132--UPDATE动作要申请的锁(1)USE [AdventureWorks] SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRAN update_1UPDATE [dbo].[Employee_Demo_Heap]SET [Title]='changehea1213412p'WHERE [EmployeeID] IN(3,30,200)--COMMIT TRAN--ROLLBACK--从这个例子可以看出，如果update借助了哪个索引，这个索引的键值上就会有U锁,没有用到的索引上没有锁。--,DATABASE,S, --Employee_Demo_Heap,OBJECT,IX, --Employee_Demo_Heap,KEY,U,(76bc6173e51d) --Employee_Demo_Heap,KEY,U,(ec8f0458157e) --Employee_Demo_Heap,KEY,U,(8d9ce4e03eca) --Employee_Demo_Heap,PAGE,IU,1:24190 --Employee_Demo_Heap,RID,X,1:24188:29 --Employee_Demo_Heap,RID,X,1:24374:16 --Employee_Demo_Heap,RID,X,1:24188:2 --Employee_Demo_Heap,PAGE,IX,1:24188 --Employee_Demo_Heap,PAGE,IX,1:24374 --在非聚集索引上申请了3个U锁这 通过非聚集索引PK_Employee_EmployeeID_Demo_Heap（index_id是2）找到了这3条记录--在RID上申请了3个X锁。数据RID上有了修改，所以RID上加的是X锁，其他索引上没有加锁--对于查询涉及的页面，SQL加了IU锁意向更新锁，修改发生的页面，SQL加了IX锁 意向排他锁 （先查询再修改）锁key 锁索引键值 因为修改的列没有被索引 实验2123456789101112131415161718192021222324--UPDATE动作要申请的锁(2)--DROP INDEX [Employee_Demo_BTree_Title] ON [AdventureWorks].[dbo].[Employee_Demo_BTree]USE [AdventureWorks]SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRAN update_2UPDATE [dbo].[Employee_Demo_BTree]SET [Title]='changeheap'WHERE [EmployeeID] IN(3,30,200)--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_BTree,KEY,X,(98ec012aa510) --Employee_Demo_BTree,KEY,X,(af5579654878) --Employee_Demo_BTree,KEY,X,(8034b699f2c9) --Employee_Demo_BTree,OBJECT,IX, --Employee_Demo_BTree,PAGE,IX,1:24183 --Employee_Demo_BTree,PAGE,IX,1:24361 实验3123456789101112131415161718192021222324252627282930313233343536373839404142--UPDATE动作要申请的锁(3)--如果修改的列被一个索引使用到了，会是什么情况呢？为了完成这个测试，先在Employee_Demo_BTree--上建一个会被修改的索引--CREATE NONCLUSTERED INDEX [Employee_Demo_BTree_Title] ON [AdventureWorks].[dbo].[Employee_Demo_BTree]([Title] ASC)--再运行下面语句USE [AdventureWorks]SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRAN update_3UPDATE [dbo].[Employee_Demo_BTree]SET [Title]='changeheap'WHERE [EmployeeID] IN(3,30,200)--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_BTree,OBJECT,IX, --Employee_Demo_BTree,KEY,X,(e1ec96b5ebdf) --Employee_Demo_BTree,KEY,X,(3257b8d72bb6) --Employee_Demo_BTree,KEY,X,(dfeed147c0d9) --Employee_Demo_BTree,KEY,X,(7cf149949204) --Employee_Demo_BTree,KEY,X,(e857a9082db1) --Employee_Demo_BTree,KEY,X,(c73666f49700) --Employee_Demo_BTree,KEY,X,(98ec012aa510) --Employee_Demo_BTree,KEY,X,(af5579654878) --Employee_Demo_BTree,KEY,X,(8034b699f2c9)--Employee_Demo_BTree,PAGE,IX,1:24183 --Employee_Demo_BTree,PAGE,IX,1:24361 --Employee_Demo_BTree,PAGE,IX,1:24382 --Employee_Demo_BTree,PAGE,IX,1:24379 --Employee_Demo_BTree,PAGE,IX,1:24377 --语句利用聚集索引找到要修改的3条记录.但是我们看到有9个键上有X锁。--很有意思：PK_Employee_EmployeeID_Demo_BTree（index_id=1）聚集索引，也是数据存放的地方。--UPDATE_2做的update语句没有改到他的索引列，他只需把Title这个列的值改掉。所以在index1上，只申请3个X锁，每条记录一个--但是表格在Title上面有一个非聚集索引IX_Employee_ManagerID_Demo_BTree（index_id=5）,并且Title是第一列。他被修改后，原来的索引键值就要被删除掉，并且插入新的键值。--所以在index_id=5 上要申请6个X锁，老的键值3个，新的键值3个 总结对于update语句，可以简单理解为SQL先做查询，把需要修改的记录给找到，然后在这个记录上做修改。找记录的动作要加S锁，找到修改的记录后加U锁，再将U锁升级为X锁。加锁的位置是 RID(堆表)或者CLUSTER_INDEX(聚集表) 想降低一个update语句被别人阻塞住的几率，除了注意他的查询部分之外，还要做的事情有： 尽量修改少的记录集。修改的记录越多，需要的锁也就越多 尽量减少无谓的索引。索引的数目越多，需要的锁也可能越多 但是也要严格避免表扫描的发生。如果只是修改表格记录的一小部分，要尽量使用index seek索引查找避免全表扫描这种执行计划 DELETE实验112345678910111213141516171819202122--delete动作要申请的锁（1）USE [AdventureWorks]BEGIN TRAN delete_1DELETE [dbo].[Employee_Demo_BTree]WHERE [LoginID]='adventure-works\kim1'--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_BTree,OBJECT,IX, --Employee_Demo_BTree,KEY,X,(a8fc9de67ccb) --Employee_Demo_BTree,KEY,X,(ad818e966dc0) --Employee_Demo_BTree,KEY,X,(38fd2d9689b5) --Employee_Demo_BTree,PAGE,IX,1:24361 --Employee_Demo_BTree,PAGE,IX,1:24365 --可以看到delete语句在聚集索引（index_id=1）和两个非聚集索引（index_id=2和3）上各申请了一个X锁在--所在的页面上申请了一个IX锁 实验21234567891011121314151617181920212223242526272829303132333435363738--delete动作要申请的锁（2）USE [AdventureWorks]SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRAN delete_2DELETE [dbo].[Employee_Demo_Heap]WHERE [LoginID]='adventure-works\tete0'--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_Heap,KEY,X,(a9c8ddfb091b) --Employee_Demo_Heap,KEY,X,(85b6a54957a8) --Employee_Demo_Heap,KEY,X,(c8fabd8e786b) --Employee_Demo_Heap,OBJECT,IX, --Employee_Demo_Heap,PAGE,IX,1:24360 --Employee_Demo_Heap,PAGE,IX,1:24369 --Employee_Demo_Heap,PAGE,IU,1:24188 --Employee_Demo_Heap,PAGE,IX,1:24376 --Employee_Demo_Heap,PAGE,IU,1:24375 --Employee_Demo_Heap,PAGE,IU,1:24374 --Employee_Demo_Heap,PAGE,IU,1:24373 --Employee_Demo_Heap,PAGE,IU,1:24372 --Employee_Demo_Heap,PAGE,IU,1:24371 --Employee_Demo_Heap,PAGE,IX,1:24190 --Employee_Demo_Heap,RID,X,1:24376:2--可以看到delete语句在3个非聚集索引（index_id=2、3、4）上各申请了一个X锁。--在所在的页面上申请了一个IX锁。--在修改发生的heap数据页面上，申请了一个IX锁，相应的RID上（真正的数据记录）申请了一个X锁。--如果使用repeatable read这个级别运行上面的delete命令，就能看出好像做select的时候一样，做delete的时候SQL也需要先找到要删除的记录。--在找的过程中也会加锁,描过的页面申请IU锁 总结 delete的过程是先找到记录，然后做删除。可以理解为先是一个select,然后是delete.所以,如果有合适的索引,第一步申请的锁就会比较少,不用表扫描 delete不但是把数据行本身删除,还要删除所有相关的索引键.所以一张表上索引数目越多锁的数目就会越多,也就越容易发生阻塞 为了防止阻塞,我们既不能绝对地不建索引,也不能随随便便地建立很多索引,而是要建立对查找有利的索引.对于没有使用到的索引,还是去掉比较好 INSERT实验1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354--INSERT 要申请的锁（1）USE [AdventureWorks]SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRANINSERT INTO [dbo].[Employee_Demo_Heap] ( [EmployeeID] , [NationalIDNumber] , [ContactID] , [LoginID] , [ManagerID] , [Title] , [BirthDate] , [MaritalStatus] , [Gender] , [HireDate] , [ModifiedDate] )SELECT501,480168528,1009,'adventure-works\thierry0',263,'Tool Desinger','1949-08-29 00:00:00.000','M','M','1998-01-11 00:00:00.000','2004-07-31 00:00:00.000'--COMMIT TRAN--ROLLBACK--,DATABASE,S, --Employee_Demo_Heap,OBJECT,IX, --Employee_Demo_Heap,KEY,X,(2b4f69bdcc15) --Employee_Demo_Heap,KEY,X,(82704d2b820e) --Employee_Demo_Heap,KEY,X,(6317a951a3c2) --Employee_Demo_Heap,PAGE,IX,1:24190 --Employee_Demo_Heap,PAGE,IX,1:24360 --Employee_Demo_Heap,PAGE,IX,1:24369 --Employee_Demo_Heap,RID,X,1:24376:9--Employee_Demo_Heap,PAGE,IX,1:24376 --（1）数据库上的S锁（resource_type=DATABASE）--（2）表上的IX锁（resource_type=OBJECT）--（3）每个索引上都要插入一条新数据，所以有一个key上的X锁--（4）在每个索引上发生变化的那个页面，申请了一个IX锁（resource_type=PAGE）--（5）RID锁。因为真正的数据不是放在索引上，而是放在heap数据页面上-- (6) RID 所在页面（24376）：IX锁 实验21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950--INSERT 要申请的锁（2）USE [AdventureWorks]SET TRANSACTION ISOLATION LEVEL REPEATABLE READGOBEGIN TRANINSERT INTO [dbo].[Employee_Demo_BTree] ( [EmployeeID] , [NationalIDNumber] , [ContactID] , [LoginID] , [ManagerID] , [Title] , [BirthDate] , [MaritalStatus] , [Gender] , [HireDate] , [ModifiedDate] )SELECT501,480168528,1009,'adventure-works\thierry0',263,'Tool Desinger','1949-08-29 00:00:00.000','M','M','1998-01-11 00:00:00.000','2004-07-31 00:00:00.000'--COMMIT TRAN--ROLLBACK--,DATABASE,S,--Employee_Demo_BTree,OBJECT,IX, --Employee_Demo_BTree,KEY,X,(3937e7935c85) --Employee_Demo_BTree,KEY,X,(fa64829c6a59) --Employee_Demo_BTree,KEY,X,(7e98e1db48bd) --Employee_Demo_BTree,PAGE,IX,1:24365 --Employee_Demo_BTree,PAGE,IX,1:24187 --Employee_Demo_BTree,PAGE,IX,1:24363--（1）数据库上的S锁（resource_type=DATABASE）--（2）表上的IX锁（resource_type=OBJECT）--（3）每个索引上都要插入一条新数据，所以有一个key上的X锁--（4）在每个索引上发生变化的那个页面，申请了一个IX锁（resource_type=PAGE） 总结相对于select,update,delete，单条记录的insert操作对锁的申请比较简单。SQL会为新插入的数据本身申请一个X锁，在发生变化的页面上申请一个IX锁。由于这条记录是新插入的，被其他连接引用到的概率会相对小一些，所以出现阻塞的几率也要小]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[sql server 锁(1)]]></title>
      <url>%2F2017%2F03%2F21%2Fsql-server-locks%2F</url>
      <content type="text"><![CDATA[介绍 SQL Server 的锁，阻塞以及死锁等问题。 目录 锁产生的背景 锁资源和兼容性 事务隔离级别和锁释放 监视锁申请、持有和释放 准备 实际查询中锁的申请与释放 SELECT UPDATE DELETE INSERT 锁 阻塞 死锁事务是关系型数据库的一个基础概念。他是作为单个逻辑工作单元执行的一系列操作一个逻辑工作单元必须有4个属性，称为原子性，一致性，隔离性，持久性(ACID)只有这样才能成为一个事务. 原子性 事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。比如一个事务要修改100条记录，要不就100条都修改，要不就都不修改。不能发生只修改了其中50条，另外50条没有改的情况。 一致性 事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构（如B树索引或双向链表）都必须是正确的。 隔离性 由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务识别数据所处的状态，要么是另一并发事务修改他之前的状态，要么是第二个事务修改他之后的状态，事务不会识别中间状态的数据。也就是说，虽然用户是在并发操作，但是，事务是串行执行的。对同一个数据对象的操作，事务读写修改是有先后顺序的。不是同一时间什么事情都能同时做的。 持久性 事务完成之后，他对于系统的影响是永久性的。哪怕SQL发生了异常终止，机器掉电，只要数据库文件还是完好的，事务做的修改必须还全部存在。 以上事务的定义对所有的关系型数据库都成立，不管是SQLSERVER，还是DB2，ORACLE，都要遵从这些限制。但是，不同的数据库系统在事务的实现机制上有所不同，索引产生的效果在细节上是有差异的。尤其是SQLSERVER和ORACLE，在事务的实现上有很大不同。两者在不同的应用场景上各有优劣，不好讲谁做得更好，谁做得更差。下面讲的是SQLSERVER实现事务的方法。 要实现业务逻辑上的ACID，有两方面任务： 1、数据库程序员要负责启动和结束事务，确定一个事务的范围:程序员要定义数据修改的顺序，将组织的业务规则用TSQL语句表现出来，然后将这些语句包括到一个事务中。换句话说，数据库程序员负责在必要并且合适的时间开启一个事务，将要做的操作以正确的顺序提交给SQLSERVER，然后在合适的时间结束这个事务。 2、SQLSERVER数据库引擎强制该事务的物理完整性:数据库引擎有能力提供一种机制，保证每个逻辑事务的物理完整性SQLSERVER通过下面方法做到： 锁定资源，使事务保持隔离 SQLSERVER通过在访问不同资源时需要申请不同类型锁的方式，实现了不同事务之间的隔离。如果两个事务会互相影响，那么在其中一个事务申请到了锁以后，另外一个事务就必须等待，直到前一个事务做完为止。 先写入日志方式，保证事务的持久性 SQLSERVER通过先写入日志的方式，保证所有提交了的事务在硬盘上的日志文件里都有记录。即使服务器硬件，操作系统或数据库引擎实例自身出现故障，该实例也可以在重新启动时使用事务日志，将所有未完成的事务自动地回滚到系统出现故障的点，使得数据库进入一个从事务逻辑上来讲一致的状态。 事务管理特性，强制保证事务的原子性和一致性 事务启动后，就必须成功完成，否则数据库引擎实例将撤销该事务启动之后对数据所做的所有修改。 如果一个连接没有提交事务，SQL会保持这个事务一直在活动状态，并且不在意这个事务的长短或这个连接是否还在活动，直到这个连接自己提交事务，或登出（logout）SQLSERVER如果在登出的时候还有未提交的事务，SQL会把这个事务范围内所做的所有操作撤销（回滚）。 所以，锁是SQL实现事务隔离的一部分，阻塞正是事务隔离的体现。要实现事务的隔离，阻塞不是SQLSERVER自找的，而是事务对SQLSERVER提出的要求，也是用户使用事务要付出的代价一个数据库开发者和DBA的工作，不是去消除阻塞，而是要把阻塞的时间和范围控制在一个合理的范围之内，使最终用户既能享受事务的ACID，又能享受预期的性能。完全消除阻塞，是不可能的事情。 换句话说，阻塞是实现事务的隔离所带来的不可避免的代价。为了达到良好的性能，数据库开发者和DBA要把阻塞的时间和范围控制在一个合理的范围之内。这不是一件很简单的工作，所以阻塞也将会是SQLSERVER的永恒的话题之一。 阻塞和死锁是两个不同的概念: 阻塞是由于资源不足引起的排队等待现象。 死锁是由于两个对象在拥有一份资源的情况下申请另一份资源，而另一份资源恰好又是这两对象正持有的，导致两对象无法完成操作，且所持资源无法释放。例如： 事务 A 获取了行 1 的共享锁。 事务 B 获取了行 2 的共享锁。 现在，事务 A 请求行 2 的排他锁，但在事务 B 完成并释放其对行 2 持有的共享锁之前被阻塞。 现在，事务 B 请求行 1 的排他锁，但在事务 A 完成并释放其对行 1 持有的共享锁之前被阻塞。 对于一个多用户数据库系统，尤其是大量用户通过不同应用程序同时访问同一个数据库的系统如果发生一个或多个以下现象，管理员就应该检查是否遇到了阻塞或者死锁了: 并发用户少的时候，一切正常。但是随着并发用户的增加，性能越来越慢 客户端经常收到以下错误 错误1222:已经超过了锁请求超时时段 错误1205:事务（进程ID XXX）与另一个进程被死锁在XX资源上，并且已被选作死锁牺牲品。请重新运行该事务 超时错误:timeout expired.the timeout period elapsed prior to completion of the operation orthe server is not responding 应用程序运行很慢，但是SQL这里CPU和硬盘利用率很低。DBA运行sp_who或sp_who2这样的短小命令很快返回 有些查询能够进行，但是有些特定的查询或修改总是不能返回 重启SQL就能解决。但是有可能跑一段时间以后又会出问题 锁在一个连接里的生命周期是和事务的生命周期紧密相连的，数据结构不同，SQLSERVER需要申请的锁的数量也会不同 造成阻塞和死锁的3大原因： 连接持有锁时间过长 锁数目过多 锁粒度过大 至于如何才能避免产生严重的阻塞和死锁问题，应该从下面3个方面着手: 申请资源的互斥度:如果不同的连接申请的锁都是相互兼容的，那么他们就不会产生阻塞 锁的范围和数目的多少:做同样一件事情，SQLSERVER申请的锁的粒度和数目可能会不一样。一个良好设计的程序可以使申请的锁的粒度和数目控制在最小的范围之内。这样，阻塞住别人的可能性就能大大降低 事务持有锁资源的时间长短:如果一个锁是大家都需要用的，那么每个人持有他的时间越短，阻塞对性能的影响就会越小。最好是申请得越晚越好，释放得越早越好 为了达到以上3个目的，需要研究一下SQLSERVER的锁资源模式和兼容性，以及他们怎么被申请和释放的。 锁资源和兼容性锁粒度和层次结构下表列出了数据库引擎可以锁定的资源。 资源 说明 RID 用于锁定堆中的单个行的行标识符。 KEY 索引中用于保护可序列化事务中的键范围的行锁。 PAGE 数据库中的 8 KB 页，例如数据页或索引页。 EXTENT 一组连续的八页，例如数据页或索引页。 HoBT 堆或 B 树。 用于保护没有聚集索引的表中的 B 树（索引）或堆数据页的锁。 TABLE 包括所有数据和索引的整个表。 FILE 数据库文件。 APPLICATION 应用程序专用的资源。 METADATA 元数据锁。 ALLOCATION_UNIT 分配单元。 DATABASE 整个数据库。 锁模式 锁模式 说明 共享 (S) 用于不更改或不更新数据的读取操作，如 SELECT 语句。 更新 (U) 用于可更新的资源中。 防止当多个会话在读取、锁定以及随后可能进行的资源更新时发生常见形式的死锁。 排他 (X) 用于数据修改操作，例如 INSERT、UPDATE 或 DELETE。 确保不会同时对同一资源进行多重更新。 意向 用于建立锁的层次结构。 意向锁包含三种类型：意向共享 (IS)、意向排他 (IX) 和意向排他共享 (SIX)。 架构 在执行依赖于表架构的操作时使用。 架构锁包含两种类型：架构修改 (Sch-M) 和架构稳定性 (Sch-S)。 大容量更新 (BU) 在向表进行大容量数据复制且指定了 TABLOCK 提示时使用。 键范围 当使用可序列化事务隔离级别时保护查询读取的行的范围。 确保再次运行查询时其他事务无法插入符合可序列化事务的查询的行。 共享锁共享锁（S 锁）允许并发事务在封闭式并发控制下读取 (SELECT) 资源。 有关详细信息，请参阅并发控制的类型。 资源上存在共享锁（S 锁）时，任何其他事务都不能修改数据。 读取操作一完成，就立即释放资源上的共享锁（S 锁），除非将事务隔离级别设置为可重复读或更高级别，或者在事务持续时间内用锁定提示保留共享锁（S 锁）。 更新锁更新锁（U 锁）可以防止常见的死锁。 在可重复读或可序列化事务中，此事务读取数据 [获取资源（页或行）的共享锁（S 锁）]，然后修改数据 [此操作要求锁转换为排他锁（X 锁）]。 如果两个事务获得了资源上的共享模式锁，然后试图同时更新数据，则一个事务尝试将锁转换为排他锁（X 锁）。 共享模式到排他锁的转换必须等待一段时间，因为一个事务的排他锁与其他事务的共享模式锁不兼容；发生锁等待。 第二个事务试图获取排他锁（X 锁）以进行更新。 由于两个事务都要转换为排他锁（X 锁），并且每个事务都等待另一个事务释放共享模式锁，因此发生死锁。若要避免这种潜在的死锁问题，请使用更新锁（U 锁）。 一次只有一个事务可以获得资源的更新锁（U 锁）。 如果事务修改资源，则更新锁（U 锁）转换为排他锁（X 锁）。 排他锁排他锁（X 锁）可以防止并发事务对资源进行访问。 使用排他锁（X 锁）时，任何其他事务都无法修改数据；仅在使用 NOLOCK 提示或未提交读隔离级别时才会进行读取操作。数据修改语句（如 INSERT、UPDATE 和 DELETE）合并了修改和读取操作。 语句在执行所需的修改操作之前首先执行读取操作以获取数据。 因此，数据修改语句通常请求共享锁和排他锁。 例如，UPDATE 语句可能根据与一个表的联接修改另一个表中的行。 在此情况下，除了请求更新行上的排他锁之外，UPDATE 语句还将请求在联接表中读取的行上的共享锁。 意向锁数据库引擎使用意向锁来保护共享锁（S 锁）或排他锁（X 锁）放置在锁层次结构的底层资源上。 意向锁之所以命名为意向锁，是因为在较低级别锁前可获取它们，因此会通知意向将锁放置在较低级别上。意向锁有两种用途：防止其他事务以会使较低级别的锁无效的方式修改较高级别资源。提高数据库引擎在较高的粒度级别检测锁冲突的效率。例如，在该表的页或行上请求共享锁（S 锁）之前，在表级请求共享意向锁。 在表级设置意向锁可防止另一个事务随后在包含那一页的表上获取排他锁（X 锁）。 意向锁可以提高性能，因为数据库引擎仅在表级检查意向锁来确定事务是否可以安全地获取该表上的锁。 而不需要检查表中的每行或每页上的锁以确定事务是否可以锁定整个表。意向锁包括意向共享 (IS)、意向排他 (IX) 以及意向排他共享 (SIX)。 锁模式 说明 意向共享 (IS) 保护针对层次结构中某些（而并非所有）低层资源请求或获取的共享锁。 意向排他 (IX) 保护针对层次结构中某些（而并非所有）低层资源请求或获取的排他锁。 IX 是 IS 的超集，它也保护针对低层级别资源请求的共享锁。 意向排他共享 (SIX) 保护针对层次结构中某些（而并非所有）低层资源请求或获取的共享锁以及针对某些（而并非所有）低层资源请求或获取的意向排他锁。 顶级资源允许使用并发 IS锁,例如，获取表上的 SIX 锁也将获取正在修改的页上的意向排他锁以及修改的行上的排他锁。 虽然每个资源在一段时间内只能有一个 SIX 锁，以防止其他事务对资源进行更新，但是其他事务可以通过获取表级的 IS 锁来读取层次结构中的低层资源。 意向更新 (IU) 保护针对层次结构中所有低层资源请求或获取的更新锁。 仅在页资源上使用 IU 锁。 如果进行了更新操作，IU 锁将转换为 IX 锁。 共享意向更新 (SIU) S 锁和 IU 锁的组合，作为分别获取这些锁并且同时持有两种锁的结果。 例如，事务执行带有 PAGLOCK 提示的查询，然后执行更新操作。 带有 PAGLOCK 提示的查询将获取 S 锁，更新操作将获取 IU 锁。 更新意向排他 (UIX) U 锁和 IX 锁的组合，作为分别获取这些锁并且同时持有两种锁的结果。 锁兼容性 完整的锁兼容性矩阵 键范围锁定键范围锁定 事务隔离级别和锁释放数据库有并发操作的时候，修改数据的事务会影响同时要去读取或修改相同数据的其他事务。如果数据存储系统并没有并发控制，则事务可能会看到以下负面影响： 丢失更新 未提交的依赖关系（脏读） 不一致的分析（不可重复读） 幻读 上面4种情况的定义可以在SQL联机丛书里找到。当许多人试图同时修改数据库中的数据时，必须实现一个控制系统，使一个人所做的修改不会对他人所做的修改产生负面影响，这就称为并发控制。 需要注意的是，不同性质的应用程序对并发控制会有不一样的需求。例如一个银行ATM系统，可能就不允许不可重复读的出现。而一个报表系统，可能对脏读的敏感度不会那么高。要防止的负面影响越多，隔离级别就越高，程序的并发性也就越差。并不是每个应用程序都需要将上面4种问题全部避免。 数据库系统通过定义事务的隔离级别来定义使用哪一级的并发控制。SQL-99标准定义了下列隔离级别，SQL数据库引擎支持所有这些隔离级别： 未提交读（隔离事务的最低级别，只能保证不读取物理上损坏的数据） 已提交读（数据库引擎的默认级别，可以防止脏读） 可重复读 可序列化（隔离事务的最高级别，可防止幻影，事务之间完全隔离） 表 ：不同隔离级别允许的并发副作用|隔离级别| |脏读 |不可重复读 |幻读|| :——————–:| :—————–: |:—————–: |:—————–: ||未提交读(nolock) |否 |是 |是||已提交读 |否 |是 |是||可重复读 |否 |否 |是||可序列化 |否 |否 |否| 未提交读（read uncommitted）指定语句可以读取已由其他事务修改但尚未提交的行。也就是说，允许脏读在read uncommitted级别运行的事务，不会发出共享锁来防止其他事务修改当前事务读取的数据。read committed事务也不会被排他锁阻塞。共享锁会禁止当前事务读取其他事务已修改但尚未提交的行。设置此选项后，此事务可以读取其他事务未提交的修改。在事务结束之前，其他事务可以更改数据中的值。该选项的作用与在事务内所有select语句中的所有表上设置nolock相同。这是隔离级别中限制最少的级别。换句话说，未提交读的意思也就是：读的时候不申请共享锁。所以他不会被其他人的排他锁阻塞，他也不会阻塞别人申请排他锁 已提交读（read committed）指定语句不能读取已由其他事务修改但尚未提交的数据.这样可以避免脏读。其他事务可以在当前事务的各个语句之间更改数据，从而产生不可重复读取数据和幻象数据。该选项是SQL的默认设置。数据库引擎会在读的时候使用共享锁防止其他事务在当前事务执行读取操作期间修改行。共享锁还会阻止语句在其他事务完成之前读取由这些事务修改的行。但是，语句运行完毕后便会释放共享锁，而不是等到事务提交的时候但是SQL默认设置是每一语句运行完毕就提交事务。 可重复读（repeatable read）指定语句不能读取已由其他事务修改但尚未提交的行，并且指定，其他任何事务都不能在当前事务完成之前修改由当前事务读取的数据。在这个隔离级别上，对事务中的每个语句所读取的全部数据都设置了共享锁，并且该共享锁一直保持到事务完成为止。这样可以防止其他事务修改当前事务读取的任何行。其他事务可以插入与当前事务所发出语句的搜索条件相匹配的新行。如果当前事务随后重试执行该语句，他会检索新行，从而产生幻读。由于共享锁一直保持到事务结束，而不是每个语句结束时释放，所以并发性低于默认的read committed隔离级别。此选项只在必要时使用。 可序列化（serializable）可序列化的要求：语句不能读取已由其他事务修改但尚未提交的数据。任何其他事务都不能在当前事务完成之前修改由当前事务读取的数据在当前事务完成之前，其他事务不能使用当前事务中任何语句读取的键值插入新行。SQL通过加范围锁的方式来实现可序列化。范围锁处于与事务中执行的每个语句的搜索条件相匹配的键值范围之内。这样可以阻止其他事务更新或插入任何行，从而限定当前事务所执行的任何语句。这意味着如果再次执行事务中的任何语句，则这些语句便会读取同一组行。在事务完成之前将一直保持范围锁。这是限制最多的隔离级别，因为他锁定了键的整个范围，并在事务完成之前一直保持范围锁。因为并发级别最低，所以应只在必要时才使用该选项。该选项的作用与在事务内所有select语句中的所有表上设置holdlock相同。 SQLSERVER其实通过对共享锁申请和释放机制的不同处理，来实现不同事务隔离级别的 不同隔离级别对共享锁的不同处理方式： 隔离级别 是否申请共享锁 何时释放 有无范围锁 未提交读 不申请 无 无 已提交读 申请 当前语句做完时 无 可重复读 申请 事务提交时 无 可序列化 申请 事务提交时 有 也就是说，事务隔离级别越高，共享锁被持有的时间越长。而可序列化还要申请粒度更高的范围锁，并一直持有到事务结束。所以，如果阻塞发生在共享锁上面，可以通过降低事务隔离级别得到缓解。 需要说明的是，SQL在处理排他锁的时候，4个事务隔离级别都是一样的。都是在修改的时候申请直到事务提交的时候释放（而不是语句结束以后就立即释放）。如果阻塞是发生在排他锁上面，是不能通过降低事务隔离级别得到缓解的。 监视锁申请、持有和释放123456789101112131415161718USE [AdventureWorks2014] --要查询申请锁的数据库GOSELECT[request_session_id],c.[program_name],DB_NAME(c.[dbid]) AS dbname,[resource_type],[request_status],[request_mode],[resource_description],OBJECT_NAME(p.[object_id]) AS objectname,p.[index_id]FROM sys.[dm_tran_locks] AS a LEFT JOIN sys.[partitions] AS pON a.[resource_associated_entity_id]=p.[hobt_id]LEFT JOIN sys.[sysprocesses] AS c ON a.[request_session_id]=c.[spid]WHERE c.[dbid]=DB_ID()ORDER BY [request_session_id],[resource_type] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364SELECT GETDATE()AS 'current_time', es.session_id, db_name(sp.dbid)AS database_name, es.status, substring((SELECT text FROM sys.dm_exec_sql_text(sp.sql_handle)), 1, 128)AS sql_text, es.host_name, es.login_time, es.login_name, es.program_name, Convert(float, Round((IsNull(es.cpu_time, 0.0)/1000.00), 0))AS cpu_time_in_seconds, Convert(float, Round((IsNull(es.lock_timeout, 0.0)/1000.00), 0))AS lock_timeout_in_seconds, tl.resource_type AS lock_type, tl.request_mode, tl.resource_associated_entity_id, CASE WHEN tl.resource_type = 'OBJECT' THEN OBJECT_NAME(tl.resource_associated_entity_id) WHEN tl.resource_type IN ('KEY', 'PAGE', 'RID') THEN (SELECT object_name(object_id) FROM sys.partitions ps1 WHERE ps1.hobt_id = tl.resource_associated_entity_id) ELSE 'n.a.' END AS object_name, tl.request_status, ec.connect_time, ec.net_transport, ec.client_net_address, er.connection_id, CASE er.blocking_session_id WHEN 0 THEN 'Not Blocked' WHEN-2 THEN 'Orphaned Distributed Transaction' WHEN-3 THEN 'Deferred Recovery Transaction' WHEN-4 THEN 'Latch owner not determined' ELSE '' END AS blocking_type, er.wait_type, Convert(float, Round((IsNull(er.wait_time, 0.0)/1000.00), 0))AS wait_time_in_seconds, er.percent_complete, er.estimated_completion_time, Convert(float, Round((IsNull(er.total_elapsed_time, 0.0)/1000.00), 0))AS total_elapsed_time_in_seconds, CASE er.transaction_isolation_level WHEN 0 THEN 'Unspecified' WHEN 1 THEN 'ReadUncomitted' WHEN 2 THEN 'ReadCommitted' WHEN 3 THEN 'Repeatable' WHEN 4 THEN 'Serializable' WHEN 5 THEN 'Snapshot' ELSE '' END transaction_isolation_level FROM master.sys.dm_exec_sessions es INNER JOIN master.sys.sysprocesses sp ON sp.spid = es.session_id LEFT JOIN master.sys.dm_exec_connections ec ON ec.session_id = es.session_id LEFT JOIN master.sys.dm_exec_requests er ON er.session_id = es.session_id LEFT JOIN master.sys.dm_tran_locks tl ON tl.request_session_id = es.session_idWHERE es.session_id &lt;&gt; @@spidAND es.session_id = es.session_idAND sp.dbid = db_id()/* CURRENT DB TO MONITOR */AND tl.resource_type &lt;&gt; 'DATABASE'; 123456789101112131415161718192021222324252627282930313233SELECT CASE dtl.request_session_id WHEN - 2 THEN 'orphaned distributed transaction' WHEN - 3 THEN 'deferred recovery transaction' ELSE dtl.request_session_id END AS spid ,db_name(dtl.resource_database_id) AS databasename ,so.NAME AS lockedobjectname ,dtl.resource_type AS lockedresource ,dtl.resource_description AS lockedresourceinfo ,dtl.request_mode AS locktype ,st.TEXT AS sqlstatementtext ,es.login_name AS loginname ,es.host_name AS hostname ,CASE tst.is_user_transaction WHEN 0 THEN 'system transaction' WHEN 1 THEN 'user transaction' END AS user_or_system_transaction ,at.NAME AS transactionname ,dtl.request_statusFROM sys.dm_tran_locks dtlJOIN sys.partitions sp ON sp.hobt_id = dtl.resource_associated_entity_idJOIN sys.objects so ON so.object_id = sp.object_idJOIN sys.dm_exec_sessions AS es ON es.session_id = dtl.request_session_idJOIN sys.dm_tran_session_transactions AS tst ON es.session_id = tst.session_idJOIN sys.dm_tran_active_transactions at ON tst.transaction_id = at.transaction_idJOIN sys.dm_exec_connections ec ON ec.session_id = es.session_idCROSS APPLY sys.dm_exec_sql_text(ec.most_recent_sql_handle) AS stWHERE resource_database_id = db_id()ORDER BY dtl.request_session_id]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[3.SQL Server基本管理单位:区(Extend)]]></title>
      <url>%2F2017%2F03%2F21%2Fsql-server-extend-management%2F</url>
      <content type="text"><![CDATA[区就是一组8个页(8K),因此区是64k的块。SQL Server内部有2类区： 混合区 统一区 全局分配映射表（GAM: Global Allocation Map Pages） ：GAM页记录哪些些区已被使用分配。对于每个区，GAM都有一个位。如果这个位是1，表示对应的区是空闲可用的。如果这个位是0，表示对应区被统一区或混合区使用。一个GAM页可以保存64000个区的使用信息。这就是说，一个GAM可以保存近4G（64000 8 8/ 1024)数据文件的使用信息。简单来说，一个7G的数据文件会有2个GAM页。 共享全局分配映射表（SGAM: Shared Global Allocation Map Pages） ：SGAM页记录哪些区已被作为混合区使用并至少有一个可用的空闲页。对于每个区，SGAM都有一个位。如果这个位是1，表示对应的区作为混合区使用并至少有一个可用的空闲页。如果这个位是0，表示这个区既没被混合区使用（作为统一区），或这个区的所有页都作为混合区使用了。一个SGAM页可以保存64000个区的使用信息。这就是说，一个SGAM可以保存近4G（64000 8 8/ 1024)数据文件的使用信息。简单来说，一个7G的数据文件会有2个SGAM页。 GAM和SGAM页帮助数据库引擎进行区管理。分配一个区，数据库引擎查找标记1的GAM页，然后标记为0。如果那个区是作为混合区分配，它会在SGAM页把对应区的标记为1。如果那个区是作为统一区分配，那就没有必要在SGAM里修改对应位标记。找一个有空页的混合区，数据库引擎在SGAM页查找标记为1的位。如果没找到，数据文件已经满了。解除一个区分配，数据库引擎会把对应GAM页里对应位设置为1，SGAM页里对应标记设置为0。 在每个数据文件里，第3个页（页号2，页号从0开始）是GAM页，第4个页（页号3，页号从0开始）是SGAM页。第1个页（页号0）是文件头（file header），第2个页（页号1）是PFS（Page Free Space）页。我们可以使用DBCC PAGE命令查看GAM和SGAM页。 存储引擎揭秘SQL Server 存储理解GAM和SGAM页]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[02.SQL Server存储单位:页(Page)]]></title>
      <url>%2F2017%2F03%2F01%2Fdata-pages-the-foundation-of-sql-server%2F</url>
      <content type="text"><![CDATA[SQL Server 基本存储单位是页，一个页大小为8K。页分为不同的类型： 1 Data page 堆表和聚集索引的叶子节点数据2 Index page 聚集索引的非叶子节点和非聚集索引的所有索引记录3 Text mixed page A text page that holds small chunks of LOB values plus internal parts of text tree. These can be shared between LOB values in the same partition of an index or heap.4 Text tree page A text page that holds large chunks of LOB values from a single column value.7 Sort page 排序时所用到的临时页，排序中间操作存储数据用的。8 GAM page 全局分配映射（Global Allocation Map，GAM）页面 这些页面记录了哪些区已经被分配并用作何种用途。9 SGAM page 共享全局分配映射（Shared Global Allocation Map，GAM）页面 这些页面记录了哪些区当前被用作混合类型的区，并且这些区需含有至少一个未使用的页面。10 IAM page 有关每个分配单元中表或索引所使用的区的信息11 PFS page 有关页分配和页的可用空间的信息13 boot page 记录了关于数据库的信息，仅存于每个数据库的第9页15 file header page 记录了关于数据库文件的信息，存于每个数据库文件的第0页16 DCM page 记录自从上次全备以来的数据改变的页面，以备差异备份17 BCM page 有关每个分配单元中自最后一条 BACKUP LOG 语句之后的大容量操作所修改的区的信息 123456789101112131415161718192021222324252627282930USE [Test]GOif exists (select * from sysobjects where id = object_id(N'[dbo].[Customers]') and OBJECTPROPERTY(id, N'IsUserTable') = 1 )DROP TABLE dbo.CustomersCREATE TABLE Customers( FirstName CHAR(50) NOT NULL, LastName CHAR(50) NOT NULL, Address CHAR(100) NOT NULL, ZipCode CHAR(5) NOT NULL, Rating INT NOT NULL, ModifiedDate DATETIME NOT NULL,)GOINSERT INTO dbo.Customers ( FirstName , LastName , Address , ZipCode , Rating , ModifiedDate )VALUES ( 'Philip' , 'Aschenbrenner' , 'Pichlagasse 16/6' , '1220' , 1 , '2015-03-25 02:22:51' )GO DBCC IND 命令用于查询一个存储对象的内部存储结构信息，该命令有4个参数, 前3个参数必须指定。语法如下：DBCC IND ( { ‘dbname’ | dbid }, { ‘objname’ | objid },{ nonclustered indid | 1 | 0 | -1 | -2 } [, partition_number] )第一个参数是数据库名或数据库ID。第二个参数是数据库中的对象名或对象ID，对象可以是表或者索引视图。第三个参数是一个非聚集索引ID或者 1, 0, 1, or 2. 值的含义： 0: 只显示对象的in-row data页和 in-row IAM 页。 1: 显示对象的全部页, 包含IAM 页, in-row数据页, LOB 数据页row-overflow 数据页 . 如果请求的对象含有聚集所以则索引页也包括。 -1: 显示全部IAM页,数据页, 索引页 也包括 LOB 和row-overflow 数据页。 -2: 显示全部IAM页。 Nonclustered index ID:显示索引的全部 IAM页, data页和索引页，包含LOB和 row-overflow数据页。为了兼容sql server 2000,第四个参数是可选的,该参数用于指定一个分区号.如果不给定值或者给定0, 则显示全部分区数据。和DBCC PAGE不同的是, SQL Server运行DBCC IND不需要开启3604跟踪标志.结果中 Page type: 1 = data page, 2 = index page, 3 = LOB_MIXED_PAGE, 4 = LOB_TREE_PAGE, 10 = IAM page 1DBCC IND('InternalStorageFormat','Customers',-1) 结果如下： PageFID PagePID IAMFID IAMPID ObjectID 1 150 NULL NULL 261575970 1 147 1 150 261575970 IndexID PartitionNumber PartitionID iam_chain_type PageType 0 1 72057594040614912 In-row data 10 0 1 72057594040614912 In-row data 1 IndexLevel NextPageFID NextPagePID PrevPageFID PrevPagePID NULL 0 0 0 0 0 0 0 0 0 DBCC Page 命令读取数据页结构的命令DBCC Page。该命令为非文档化的命令，具体如下： DBCC Page ({dbid|dbname},filenum,pagenum[,printopt]) 具体参数描述如下： dbid 包含页面的数据库ID dbname 包含页面的数据库的名称 filenum 包含页面的文件编号 pagenum 文件内的页面 printopt 可选的输出选项;选用其中一个值： 0:默认值，输出缓冲区的标题和页面标题 1:输出缓冲区的标题、页面标题(分别输出每一行)，以及行偏移量表 2:输出缓冲区的标题、页面标题(整体输出页面)，以及行偏移量表 3:输出缓冲区的标题、页面标题(分别输出每一行)，以及行偏移量表;每一行后跟分别列出的它的列值 要想看到这些输出的结果，还需要设置DBCC TRACEON(3604)。可以使用 WITH TABLERESULTS 显示成表格化的数据形式 123DBCC TRACEON(3604)DBCC PAGE(InternalStorageFormat,1,41,1) GO 结果如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162DBCC 执行完毕。如果 DBCC 输出了错误信息，请与系统管理员联系。PAGE: (1:147)BUFFER:BUF @0x00000001FEEBDEC0bpage = 0x0000000184E2E000 bhash = 0x0000000000000000 bpageno = (1:147)bdbid = 16 breferences = 0 bcputicks = 0bsampleCount = 0 bUse1 = 36342 bstat = 0xbblog = 0x215acccc bnext = 0x0000000000000000 PAGE HEADER:Page @0x0000000184E2E000m_pageId = (1:147) m_headerVersion = 1 m_type = 1m_typeFlagBits = 0x0 m_level = 0 m_flagBits = 0x8000m_objId (AllocUnitId.idObj) = 121 m_indexId (AllocUnitId.idInd) = 256 Metadata: AllocUnitId = 72057594045857792 Metadata: PartitionId = 72057594040614912 Metadata: IndexId = 0Metadata: ObjectId = 261575970 m_prevPage = (0:0) m_nextPage = (0:0)pminlen = 221 m_slotCnt = 1 m_freeCnt = 7870m_freeData = 320 m_reservedCnt = 0 m_lsn = (34:364:23)m_xactReserved = 0 m_xdesId = (0:0) m_ghostRecCnt = 0m_tornBits = 0 DB Frag ID = 1 Allocation StatusGAM (1:2) = ALLOCATED SGAM (1:3) = ALLOCATED PFS (1:1) = 0x61 MIXED_EXT ALLOCATED 50_PCT_FULL DIFF (1:6) = CHANGEDML (1:7) = NOT MIN_LOGGED Slot 0 Offset 0x60 Length 224Record Type = PRIMARY_RECORD Record Attributes = NULL_BITMAP Record Size = 224Memory Dump @0x0000000011C7A0600000000000000000: 1000dd00 576f6f64 79202020 20202020 20202020 ....Woody 0000000000000014: 20202020 20202020 20202020 20202020 20202020 0000000000000028: 20202020 20202020 20202020 20205475 20202020 Tu 000000000000003C: 20202020 20202020 20202020 20202020 20202020 0000000000000050: 20202020 20202020 20202020 20202020 20202020 0000000000000064: 20202020 5a554f51 49414f20 594f5558 4920544f ZUOQIAO YOUXI TO0000000000000078: 574e204c 494e4841 49204349 54592020 20202020 WN LINHAI CITY 000000000000008C: 20202020 20202020 20202020 20202020 20202020 00000000000000A0: 20202020 20202020 20202020 20202020 20202020 00000000000000B4: 20202020 20202020 20202020 20202020 20202020 00000000000000C8: 20202020 30303030 20010000 001480a7 0091a400 0000 ...........00000000000000DC: 00060000 .... Slot 0 Column 1 Offset 0x4 Length 50 Length (physical) 50FirstName = WoodySlot 0 Column 2 Offset 0x36 Length 50 Length (physical) 50LastName = Tu Slot 0 Column 3 Offset 0x68 Length 100 Length (physical) 100Address = ZUOQIAO YOUXI TOWN LINHAI CITY Slot 0 Column 4 Offset 0xcc Length 5 Length (physical) 5ZipCode = 0000 Slot 0 Column 5 Offset 0xd1 Length 4 Length (physical) 4Rating = 1 Slot 0 Column 6 Offset 0xd5 Length 8 Length (physical) 8ModifiedDate = 2015-05-07 10:09:51.000 OFFSET TABLE:Row - Offset 0 (0x0) - 96 (0x60) DBCC 执行完毕。如果 DBCC 输出了错误信息，请与系统管理员联系。 Page @0x08F84000 同BUFFER中的bpage地址m_pageId = (1:79) 数据页号m_headerVersion = 1 头文件版本号，一直为1m_type = 1 页面类型，1为数据页面m_typeFlagBits = 0x4 数据页和索引页为4，其他页为0m_level = 0 该页在索引页（B树）中的级数m_flagBits = 0x8000 页面标志m_objId (AllocUnitId.idObj) = 46 同Metadata: ObjectIdm_indexId (AllocUnitId.idInd) = 256 同Metadata: IndexIdMetadata: AllocUnitId = 72057594040942592 存储单元的ID,sys.allocation_units.allocation_unit_idMetadata: PartitionId = 72057594039304192 数据页所在的分区号，sys.partitions.partition_idMetadata: IndexId = 0 页面的索引号，sys.objects.object_id&amp;sys.indexes.index_idMetadata: ObjectId = 277576027 该页面所属的对象的id，sys.objects.object_idm_prevPage = (0:0) 该数据页的前一页面；主要用在数据页、索引页和IAM页m_nextPage = (0:0) 该数据页的后一页面；主要用在数据页、索引页和IAM页pminlen = 221 定长数据所占的字节数m_slotCnt = 2 页面中的数据的行数m_freeCnt = 7644 页面中剩余的空间m_freeData = 544 从第一个字节到最后一个字节的空间字节数m_reservedCnt = 0 活动事务释放的字节数m_lsn = (255:8406:2) 日志记录号m_xactReserved = 0 最新加入到m_reservedCnt领域的字节数m_xdesId = (0:0) 添加到m_reservedCnt的最近的事务idm_ghostRecCnt = 0 幻影数据的行数m_tornBits = 0 页的校验位或者被由数据库页面保护形式决定分页保护位取代 GAM (1:2) = ALLOCATED 在GAM页上的分配情况SGAM (1:3) = ALLOCATED 在SGAM页上的分配情况PFS (1:1) = 0x61 MIXED_EXT ALLOCATED 50_PCT_FULL 在PFS页上的分配情况，该页为50%满，DIFF (1:6) = CHANGEDML (1:7) = NOT MIN_LOGGED 查看空间占用情况free_space_in_bytes 表示在指定页面当前有多少空间是可用的。 1SELECT * FROM sys.dm_os_buffer_descriptors 下面这个查询可以告诉你在你的数据库实例里每个数据有多少空间被浪费，可以找出哪个数据库有糟糕的表设计。12345678SELECTDB_NAME(database_id),SUM(free_space_in_bytes) / 1024 AS 'Free_KB'FROM sys.dm_os_buffer_descriptorsWHERE database_id &lt;&gt; 32767GROUP BY database_idORDER BY SUM(free_space_in_bytes) DESCGO 第1个页，页号0，是文件头（page type 15）。它保存着文件头信息。每个数据文件只有一个文件头页，而且是第0页的位置。文件头页里保存着数据文件信息，例如文件大小，最小大小，最大大小和文件增长方式等。 第2个页，页号1，是第一个PFS页（page type 11）。PFS页在数据文件里是第2个页（页号1），紧跟在文件头后（页号0）。GAM和SGAM用来跟踪区分配状态，PFS页用来跟踪页分配级别。当分配页面的时候，数据库引擎使用GAM和SGAM来识别有空页的区。一旦数据库引擎找到有空页的区，它使用PFS页来识别区里空页的可用空间量。可用空间只在保存LOB值（ie text/image, varchar(max),nvarchar(max),varbinary(max) ,row overflow data）或堆表页时跟踪。默认情况下，LOB数据保存在一个独立的页，在原页保存一个指向独立页的指针。这些就是数据能够保存的空页。对于索引页，因为数据的保存顺序和索引顺序是一致的，因此没有必用使用到PFS页。PFS页每8088个页重复一个。这就是说第1页，第8088页，第16176页，第24264页……在每个数据文件里都是PFS页。SQL Server： 理解PFS页。 第3个页，页号2，是第一个GAM页（page type 8）。GAM页用来跟踪哪些区被使用。每个区对应GAM页的一个位。如果这个位的值是1，对应区是空、可用的，如果这个位的值是0，对应区是作为统一区或混合区使用。一个GAM页可以保存接近64000个区的信息。那就是说，一个GAM页可以保存（64000 8 8）/1024 = 4000 MB的信息。简而言之，一个7GB大小的数据文件将有2个GAM页。SQL Server ： 理解GAM与SGAM页。 第4个页，页号3，是第一个SGAM页（page type 9）。SGAM页用来跟踪哪些区正作为混合区使用且至少有一个可用页。每个区对应一个GAM页的有一个位。如果这个位的值是1，对应区作为混合区使用且至少有个可用页，如果这个位值是0，对应区没作为混合区使用或所有页作为混合区使用了。一个SGAM页可以保存接近64000个区的信息。那就是说，一个SGAM页可以保存64000 8 8 /1024 =4000MB。简而言之，一个7GB大小的数据文件将有2个SGAM页。SQL Server ： 理解GAM与SGAM页。 第5个、6个页，（页号4,5），在SQL Server架构里当前没有被使用。页类型是0。如果用DBCC PAGE命令查看这些页只会输出页头信息，并以非法页类型结束。 第7个页，页号6，是第一个DCM页（page type 16）。SQL Server使用DCM页来跟踪自上次完整备份后，修改过的区信息。每个区对应DCM页里的一个位。如果这个位的值1，对应区自上一次完整备份后，已被修改。如果这个位值是0，对应区自上一次完整备份后，未作修改。一个DCM页可以保存接近64000个区的信息。每511232个页，DCM页会重复一个。一个DCM页可以跟踪63904个区信息。第2个DCM页出现在第511238页。SQL Server： 理解DCM页。 第8个页，页号7，是第一个BCM页（page type 17）。SQL Server使用BCM页来跟踪自上次日志备份后，通过大容量日志操作被修改的区信息。每个区对应BCM页里一个位。如果这个位的值是1，对应区自上一次日志备份后，因大容量日志操作后，这个区被修改。如果这个位的值是0，对应区自上一次日志备份后，因大容量日志操作后，这个区未被修改。一个BCM页可以保存近64000个区的信息。每511232个页，BCM页会重复一个。一个BCM页可以跟踪63904个区信息。第2个BCM页出现在第511239页。SQL Server ：理解BCM页。 第9个页，页号8，是第一个IAM页（page type 10）。IAM页是用来跟踪，指定表的分配单元的对应页或区在GAM内的分区里的分配情况。SQL Server ：理解IAM页。 第10个页，页号9，是启动页（page type 13）。启动页只出现在主数据文件（prmary data file）里的第9页，启动页不会出现在第2个数据文件里。我们可以使用DBCC PAGE命令查看它的页信息，在这个页里保存的页信息值是自说明的。如果这个页因某些原因损坏的话，我们将不能使用命令DBCC CheckDb来修复。页还原也不能改变这个情况。只能从上一次好的数据库备份中恢复才可以修复这个问题。 从第11页开始，你可以看到各种不同的页混合在一起，像数据页，索引页，IAM页，行溢出页和LOB页等等。数据页的页类型是1，索引页的页类型是2，行溢出（Row-overflow）页和LOB页的页类型是3。数据页和索引页是以同样结构保存的。SQL Server：理解数据页结构。 行溢出（Row-overflow）页用来存储不能在一页里保存的数据。LOB页用来保存大型对象，并不作为行数据的一部分来保存。 存储引擎揭秘SQL Server 存储]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[01.SQL SERVER如何执行一个查询]]></title>
      <url>%2F2017%2F03%2F01%2Fhow-sql-server-executes-a-query%2F</url>
      <content type="text"><![CDATA[根据SQLpassion推送的 SQLpassion Performance Tuning Training Plan - Week 1: How SQL Server executes a Query。记录一下对查询执行的了解。 提交查询客户端提交给数据库的查询通过SQL Server网络接口等协议层(Protocol Layer)传给命令解析器。 命令解析器(Command Parser)处理命令解释器接收到查询会做以下工作： 检查 语法正确 数据库表存在 查询列存在 生成查询树(Query Tree)：重现查询 查询树提交给查询优化器 查询优化器(Query Optimizer)处理 查询优化器将查询树编译为查询计划(Execution Plan) 将查询计划缓存到缓冲池(Buffer Pool)中的执行计划缓存区(Plan Cache) 将查询计划提交给查询执行器 查询执行器(Query Executor)处理 查询分析器根据查询计划向存取方法(Access Methods)拿指定的读取页,存取方法会向缓冲区管理器读取想要指定页。 缓存区管理器(Buffer Manager)检查它是否已在数据缓存(data cache)，如果没找到的话就从磁盘加载到缓存。 当请求的页面已经被存在缓冲池时,页会被立即读取,称为逻辑读。 如果请求的页没存在缓冲池,缓冲区管理器会发起异步I/O操作把请求的页存储子系统中读到缓冲池,称为物理读。 修改数据当修改数据(INSERT,DELETE,UPDATE)时，需要与事务管理器进行交互，事务管理器把执行事务中描述的改变通过事务日志写到事务文件。 数据缓存(Data Cache)查看每个数据库占用了多大数据缓存(sys.dm_os_buffer_descriptors) 12345678SELECT count(*)*8/1024 AS 'Cached Size (MB)' ,CASE database_id WHEN 32767 THEN 'ResourceDb' ELSE db_name(database_id) END AS 'Database'FROM sys.dm_os_buffer_descriptorsGROUP BY db_name(database_id),database_idORDER BY 'Cached Size (MB)' DESC 干净页和脏页清除干净页 1DBCC DROPCLEANBUFFERS 查询脏页 12345SELECT db_name(database_id) AS 'Database',count(page_id) AS 'Dirty Pages'FROM sys.dm_os_buffer_descriptorsWHERE is_modified =1GROUP BY db_name(database_id)ORDER BY count(page_id) DESC 参考文献understanding-how-sql-server-executes-a-query第1/24周 SQL Server 如何执行一个查询SQL Server 2012：SQL Server体系结构——一个查询的生命周期(1)SQL Server 2012：SQL Server体系结构——一个查询的生命周期(2)SQL Server 2012：SQL Server体系结构——一个查询的生命周期(3)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于备案后续]]></title>
      <url>%2F2017%2F03%2F01%2Fabout-beian-2%2F</url>
      <content type="text"><![CDATA[通过腾讯云备案，腾讯初审大约用了2天（包括提交资料和照片），然后昨天（2017年2月28日 中午12:43）腾讯正式把备案材料提交给管局审核，今天（2017年3月1日 上午10:43）就收到了审核通过的邮件和短信。真可谓快。出乎了我的想象。因为是个人备案，步骤很简单，一部手机+身份证就可以了。据说需要居住证的，也能没有要求提交，可能是放宽了政策吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于备案]]></title>
      <url>%2F2017%2F02%2F24%2Fabout-Beian%2F</url>
      <content type="text"><![CDATA[为了规范互联网信息服务活动，促进互联网信息服务健康有序发展，根据国务院令第292号《互联网信息服务管理办法》和工信部令第33号《非经营性互联网信息服务备案管理办法》规定，国家对经营性互联网信息服务实行许可制度，对非经营性互联网信息服务实行备案制度。未取得许可或者未履行备案手续的，不得从事互联网信息服务，否则就属于违法行为。 因此按照规定，需要对自己的网站进行备案。以防后面无法使用的情况发生。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Nginx运行网站]]></title>
      <url>%2F2017%2F02%2F24%2Fserver-with-nginx%2F</url>
      <content type="text"><![CDATA[hexo server 不太好用，决定使用nginx。 首先在服务器上安装nginx，以ubuntu为例。使用apt-get安装比较方便，节省很多配置。 1sudo apt-get nginx 然后开始配置nginx： 123cd /etc/nginxsudp cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.baksudo vi /etc/nginx/nginx.conf 配置内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141user www-data;worker_processes auto;pid /run/nginx.pid;events &#123; worker_connections 768; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## # log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable &quot;msie6&quot;; gzip_min_length 1k; gzip_vary on; gzip_proxied any; gzip_comp_level 6; gzip_buffers 16 8k; gzip_http_version 1.1; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Http Proxy Settings ## client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /tmp/proxy_temp 1 2; ## # Upstream Settings ## upstream backend &#123; ip_hash; server 127.0.0.1:4000 max_fails=2 fail_timeout=30s ; # server 192.168.10.101:8080 max_fails=2 fail_timeout=30s ; &#125; ## # Server Settings ## ## Server baochen.name server &#123; listen 80; server_name baochen.name; charset utf-8; access_log /var/log/nginx/baochen.name.access.log; error_log /var/log/nginx/baochen.name.error.log; location / &#123; # proxy_pass http://backend; # proxy_redirect off; # proxy_set_header Host $host; # proxy_set_header X-Real-IP $remote_addr; # proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; root /var/www/hexoblog; index index.html; &#125; location /nginx_status &#123; stub_status on; access_log /var/log/nginx/ngs.access.log; # allow 192.168.10.0/24; # deny all; &#125; location ~ ^/(WEB-INF)/ &#123; deny all; &#125; # error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; 编辑完成后 esc -&gt; !wq 退出。 编写crontab脚本: 123456789101112131415#!/bin/bash#this srcipt call by cron #will not exoprt some env var in profile or .profilerm -fr ~/update.log#execute profile. /etc/profile. ~/.profile#auto pull source code , generate and deploy to git. ~/HexoBlog/AutoUpdate.sh &gt;&gt; ~/update.log # 根据实际位置填写#deploysudo cp -r ~/HexoBlog/public/* /var/www/hexoblog # 注意权限 其中 脚本 AutoUpdate.sh 是自己随着库进行同步的 ，内容如下(之所以两个脚本原因看这里)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/bin/bash# 如果使用cron 定时call 更新脚本 # 会出现 一些定义在profile 中的环境变量无法引入的情况# 可以单独建立一个壳脚本 添加一些必要的变量 再呼叫当前脚本 AutoUpdate.sh#. /etc/profile#. ~/.profile#. ~/&lt;somepath&gt;/AutoUpdate.sh # call this srciptDEFAULT_DIR=$HOME/HexoBlogecho &quot;========================================&quot; echo $(date +%y_%m_%d_%H_%I_%T) echo &quot;----------------------------------------&quot; echo &quot;HOME : $HOME&quot;echo &quot;PATH : $PATH&quot;echo &quot;NODE_HOME : $NODE_HOME&quot;echo `whereis hexo`echo &quot;----------------------------------------&quot; if [ $1 ] ; then echo &quot;first argument is not empty : $1&quot; TAR_DIR=$1 echo &quot;use first argument as target dir : $TAR_DIR&quot; else echo &quot;first argument is empty&quot; # use $DEFAULT_DIR as the target dir TAR_DIR=$DEFAULT_DIR echo &quot;use default dir as target dir : $TAR_DIR&quot; fi echo &quot;----------------------------------------&quot; if [ -d $TAR_DIR ] ; then echo &quot;$TAR_DIR is a dir,try update&quot; cd $TAR_DIR echo &quot;++++++++++++++begin git pull++++++++++++&quot; git pull echo &quot;++++++++++++++begin hexo clean+++++++++&quot; hexo clean echo &quot;++++++++++++++begin hexo generate+++++++&quot; hexo g echo &quot;++++++++++++++begin hexo deploy+++++++++&quot; hexo d #echo &quot;++++++++++++++begin killall hexo++++++++&quot; #killall hexo #echo &quot;++++++++++++++begin hexo server+++++++++&quot; #hexo server &amp; else echo &quot;$TAR_DIR is not a dir,do nothing&quot; fiecho &quot;----------------------------------------&quot; echo $(date +%y_%m_%d_%H_%I_%T) echo &quot;========================================&quot; 然后 启动nginx ！ 1sudo service nginx start 完成！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于crontab执行脚本环境变量问题]]></title>
      <url>%2F2017%2F02%2F24%2Fabout-crontab%2F</url>
      <content type="text"><![CDATA[搭建自己的博客配置了自动化脚本，用来同步git仓库、执行hexo命令生成&amp;部署站点。 脚本内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bashDEFAULT_DIR=$HOME/HexoBlogecho &quot;========================================&quot; echo $(date +%y_%m_%d_%H_%I_%T) echo &quot;----------------------------------------&quot; echo &quot;HOME : $HOME&quot;echo &quot;PATH : $PATH&quot;echo &quot;NODE_HOME : $NODE_HOME&quot;echo `whereis hexo`echo &quot;----------------------------------------&quot; if [ $1 ] ; then echo &quot;first argument is not empty : $1&quot; TAR_DIR=$1 echo &quot;use first argument as target dir : $TAR_DIR&quot; else echo &quot;first argument is empty&quot; # use $DEFAULT_DIR as the target dir TAR_DIR=$DEFAULT_DIR echo &quot;use default dir as target dir : $TAR_DIR&quot; fi echo &quot;----------------------------------------&quot; if [ -d $TAR_DIR ] ; then echo &quot;$TAR_DIR is a dir,try update&quot; cd $TAR_DIR echo &quot;++++++++++++++begin git pull++++++++++++&quot; git pull echo &quot;++++++++++++++begin hexo clean+++++++++&quot; hexo clean echo &quot;++++++++++++++begin hexo generate+++++++&quot; hexo g echo &quot;++++++++++++++begin hexo deploy+++++++++&quot; hexo d echo &quot;++++++++++++++begin killall hexo++++++++&quot; killall hexo echo &quot;++++++++++++++begin hexo server+++++++++&quot; hexo server &amp; else echo &quot;$TAR_DIR is not a dir,do nothing&quot; fiecho &quot;----------------------------------------&quot; echo $(date +%y_%m_%d_%H_%I_%T) echo &quot;========================================&quot; 脚本中使用了nodejs中的hexo，在登录状态下，运行命令行是正常的。 这是由于在 /etc/profile 中配置了环境变量 ，添加了 NODE_HOME 、NODE_PATH 并将 NODE_HOME/bin 添加到 PATH。这样，安装的 nodejs 包（默认安装的NODE_HOME/lib/node_modules，使用npm安装同时会创建软链接到 NODE_HOME/bin）都可以直接访问到。 1234#set nodejs env export NODE_HOME=/usr/local/node export PATH=$NODE_HOME/bin:$PATH export NODE_PATH=$NODE_HOME/lib/node_modules:$PATH 但是问题在于，crontab 执行脚本时。没有用户登录（用户登录会执行 /etc/profile 和 ~/.profile）以及打开终端（打开终端会执行 /etc/bashrc 和 ~/.bashrc）的动作，需要的诸如 NODE_HOME 、NODE_PATH 等（通过/etc/profile 导入）就找不到了，PATH中也没有node的路径。 因此，这种情况下，配置 crontab 如下: 110 * * * * $HOME/CallAutoUpdate.sh # 每十分钟执行一次 其中CallAutoUpdate.sh为： 12345678#!/bin/bash# this srcipt call by cron # will not exoprt some env var in profile or .profile# so ...rm -fr ~/update.log. /etc/profile. ~/.profile. ~/HexoBlog/AutoUpdate.sh &gt;&gt; ~/update.log 这样就解决了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo搭建个人博客]]></title>
      <url>%2F2017%2F02%2F22%2Ffirst-blog%2F</url>
      <content type="text"><![CDATA[发现一个基于 Node.js的高效的静态站点生成框架Hexo,使用 Markdown 编写文章,于是用来搭建自己的网站。接下来介绍如何一步一步完成搭建的。 目录 准备 构建 创建 配置 主题 插件 写作 生成 运行 部署 准备需要在电脑中安装以下： node.js node 安装后 自带 npm 包管理器。安装方式请参考官网。 git git 用于创建hexo项目、更换主题、管理创建的hexo项目源码以及部署到github.io使用。安装方式请参考官网。 hexo-cli 用于创建、管理、发布hexo项目。使用npm包管理器安装：1npm install -g hexo-cli 构建安装完 node 、git 以及hexo-cli 后，就可以开始构建hexo blog了。 创建在源码目录下，命令行运行 1hexo init youbsitename 就可以创建名为 youbsitename 的站点目录了。此过程会clone一些项目到本地站点目录，过程如下： 1234567891011121314151617181920212223INFO Cloning hexo-starter to D:\Temp\testCloning into &apos;D:\Temp\test&apos;...remote: Counting objects: 53, done.remote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53Unpacking objects: 100% (53/53), done.Submodule &apos;themes/landscape&apos; (https://github.com/hexojs/hexo-theme-landscape.git) registered for path &apos;themes/landscape&apos;Cloning into &apos;D:/Temp/test/themes/landscape&apos;...remote: Counting objects: 764, done.remote: Compressing objects: 100% (3/3), done.remote: Total 764 (delta 0), reused 0 (delta 0), pack-reused 761Receiving objects: 100% (764/764), 2.53 MiB | 53.00 KiB/s, done.Resolving deltas: 100% (390/390), done.Submodule path &apos;themes/landscape&apos;: checked out &apos;decdc2d9956776cbe95420ae94bac87e22468d38&apos;INFO Install dependenciesnpm WARN deprecated swig@1.4.2: This package is no longer maintainednpm WARN deprecated minimatch@0.3.0: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issuenpm WARN prefer global marked@0.3.6 should be installed with -g&gt; dtrace-provider@0.8.0 install D:\Temp\test\node_modules\dtrace-provider&gt; node scripts/install.js&gt; hexo-util@0.6.0 postinstall D:\Temp\test\node_modules\hexo-util&gt; npm run build:highlight&gt; hexo-util@0.6.0 build:highlight D:\Temp\test\node_modules\hexo-util&gt; node scripts/build_highlight_alias.js &gt; highlight_alias.json 然后，进入blog目录，就可以对blog进行操作了。 1cd yousitename &amp;&amp; dir blog 目录结构如下 123456789yousitename├─package.json 项目package├─_config.yml 站点配置文件├─public 发布文件夹├─scaffolds 模版文件夹├─source 原始文件，通过&quot;hexo g&quot;将本目录下的文件生成为html等到public文件夹├─themes 主题文件夹├─...└─... 配置根目录下的站点配置文件 _config.yml 中的内容是对项目的一些配置，例如 网站信息：作者、名称、描述等 网站结构 发布方式：支持发布到git(需要插件hexo-deployer-git支持) 主题修改站点配置文件 _config.yml 中的内容：1theme: next(你想要的主题，主题需要放在站点目录下的themes目录下) 官网有提供主题列表可以选择，当然你也可以做自己的主题 另外，主题也有自己的主题配置文件 _config.yml，存放主题自己的一些配置。主题配置文件位置在主题目录下。 插件同样，hexo提供了插件功能，可以提供很多生成、发布和运行等的功能。例如可以生成静态网站后，通过插件hexo-deployer-git将生成的内容发布到git.利用这个插件搭配github.io,可以实现自动生成&amp;部署自己的网站。 写作1hexo new [layout] &lt;title&gt; Hexo 有三种默认布局：post、page 和 draft，它们分别对应不同的路径，而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。如果不想文章被布局处理，可以将 Front-Matter 中的layout: 设为 false 。 布局 路径 post source/_posts page source draft source/_drafts 更多的写作可以参考官网. 建议创建页面 : tags 和categories 页面,生成的时候可以自动生成分类)和标签页面的内容。 12hexo new page tagshexo new page categories 生成1hexo generate 或者 1hexo g 默认将静态网站生成到 public 目录下，生成完成后就可以将 public 目录下的内容发布到静态网站服务器上。 运行可以使用 hexo server 命令，本地启动服务器，运行网站 1hexo server 默认启动端口为 4000 的服务端，可以使用 http://localhost:4000 访问。 部署代码托管将创建的网站仓库托管到github，注册等过程不表。 配置自己的网站仓库，然后就可以git commit &amp; git push ,将源码推送到github上。这样就可以随时编辑自己的网站了。 不必要的内容不需要提交，可以使用 .gitignore， 贴一下自己的 .gitignore 文件: 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Logslogs*.lognpm-debug.log*# Runtime datapids*.pid*.seed# Directory for instrumented libs generated by jscoverage/JSCoverlib-cov# Coverage directory used by tools like istanbulcoverage# nyc test coverage.nyc_output# Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files).grunt# node-waf configuration.lock-wscript# Compiled binary addons (http://nodejs.org/api/addons.html)build/Release# Dependency directoriesnode_modulesjspm_packages# Optional npm cache directory.npm# Optional REPL history.node_repl_history.DS_StoreThumbs.dbdb.json*.logpublic/.deploy*/ 自动部署云服务器在云服务器(ubuntu 16.04)上安装 nodejs 、git 、hexo-cli 然后clone 到仓库本地： 12cd ~ git clone https://github.com/dp9u0/HexoBlog 创建周期执行的呼叫脚本： 1vi CallHexoBlogAutoUpdate.sh CallHexoBlogAutoUpdate.sh脚本中，添加以下内容，呼叫仓库中的自动更新脚本： 12#!/bin/bash. ~/HexoBlog/AutoUpdate.sh 为什么要有两个脚本: CallHexoBlogAutoUpdate.sh 和 AutoUpdate.sh?不知道怎么给 AutoUpdate.sh 添加权限 ，不同的操作系统clone后，权限依旧保留。同时 . ~/HexoBlog/AutoUpdate.sh 如果直接配置在 crontab 环境变量好像有点问题。因此将所以自动更新的逻辑放在 AutoUpdate.sh 并且在每个需要执行自动更新的机器上添加外壳程序 CallHexoBlogAutoUpdate.sh 用点符号执行脚本 AutoUpdate.sh。并且外壳程序添加到定时任务中。 调用的自动更新脚本（该脚本加入到git仓库中，可以自更新）： 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashLOG_FILE=~/HexoBlogAutoUpdate.logecho &quot;========================================&quot; &gt;&gt; $LOG_FILEecho $(date +%y_%m_%d_%H_%I_%T) &gt;&gt; $LOG_FILEecho &quot;----------------------------------------&quot; &gt;&gt; $LOG_FILEif [ $1 ] ; then echo &quot;first argument is not empty : $1&quot; &gt;&gt; $LOG_FILE TAR_DIR=$1 echo &quot;use first argument as target dir : $TAR_DIR&quot; &gt;&gt; $LOG_FILEelse echo &quot;first argument is empty&quot; &gt;&gt; $LOG_FILE # use ~/HexoBlog as the default dir TAR_DIR=~/HexoBlog # 修改为你需要的默认路径 echo &quot;use default dir as target dir : $TAR_DIR&quot; &gt;&gt; $LOG_FILEfi echo &quot;----------------------------------------&quot; &gt;&gt; $LOG_FILEif [ -d $TAR_DIR ] ; then echo &quot;$TAR_DIR is a dir,try update&quot; &gt;&gt; $LOG_FILE cd $TAR_DIR echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE git pull &gt;&gt; $LOG_FILE # 同步git echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE killall hexo &gt;&gt; $LOG_FILE # 关闭 hexo server echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE hexo clean &gt;&gt; $LOG_FILE # 清理 echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE hexo g &gt;&gt; $LOG_FILE # 生成 echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE hexo server &amp; # 启动 hexo server echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILE hexo d &gt;&gt; $LOG_FILE # 自动 echo &quot;++++++++++++++++++++++++++++++++++++++++&quot; &gt;&gt; $LOG_FILEelse echo &quot;$TAR_DIR is not a dir,do nothing&quot; &gt;&gt; $LOG_FILEfiecho &quot;----------------------------------------&quot; &gt;&gt; $LOG_FILEecho $(date +%y_%m_%d_%H_%I_%T) &gt;&gt; $LOG_FILEecho &quot;========================================&quot; &gt;&gt; $LOG_FILE 添加 CallHexoBlogAutoUpdate 脚本执行权限： 1chmod +x CallHexoBlogAutoUpdate.sh 添加定时任务 1crontab -e 添加如下内容 1*/5 * * * * ~/CallHexoBlogAutoUpdate.sh # 五分钟执行检查一次更新 github.iohexo deploy 命令根据站点配置文件_config.yml中的配置，将生成的内容发布到站点中。 其中不同的type需要特殊的插件支持。例如发布到git上，需要插件hexo-deployer-git 首先创建自己的github.io仓库 关于github.io:如果建立了 用户名.github.io 的仓库，github会定时将这个仓库的静态页面发布到 用户名.github.io 的站点上.可以了解更多关于 github.io的内容 站点配置文件配置参考如下： 1234deploy: type: git repo: git@github.com:dp9u0/dp9u0.github.io.git branch: master 部署到git，需要有你的github仓库的push权限，可以参考github文档中关于生成 SSH Key以及添加SSH Key的部分，配置通过SSH免密码push代码到github。 然后，就可以运行生成部署命令了。 12hexo ghexo d 这些也可以添加到AutoUpdate.sh脚本中，这样我只需要在自己的个人电脑上hexo new ,编辑自己的网站，然后git commit 提交，再执行git push到推送到 将源码推送到github上。这样就可以随时编辑自己的网站了。部署在云服务器上的网站 和github.io 上的内容，都会自动更新了！]]></content>
    </entry>

    
  
  
</search>
